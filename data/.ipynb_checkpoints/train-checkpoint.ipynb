{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4399c12-e1ac-40f9-8ebb-44d70c725106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "# from tensorflow.keras import layers \n",
    "import tensorflow_hub as hub \n",
    "# from own_dataset import get_loaders\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec6cfe7-7351-47bd-9fea-9a04e0b6d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from tqdm import tqdm \n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import WeightedRandomSampler ,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_loaders(train_dir , batch_size , image_size ):\n",
    "    print ('getting loaders')\n",
    "    train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((300,300)),\n",
    "            transforms.RandomCrop((image_size,image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.05),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    # dev_transforms = transforms.Compose([\n",
    "    #     transforms.Resize((image_size , image_size)) ,\n",
    "    #     transforms.ToTensor() ,\n",
    "        \n",
    "    # ])\n",
    "    train_dataset = datasets.ImageFolder(root = train_dir ,\n",
    "                                         transform = train_transforms\n",
    "                                        )\n",
    "    # dev_dataset = datasets.ImageFolder(root = dev_dir ,\n",
    "    #                                   transform = dev_transfrom)\n",
    "    # val_loader = DataLoader(dev_dataset , batch_size =batch_size , num_workers= 2 , pin_memory=True )\n",
    "    class_weights =[]\n",
    "    for root , subdir , files in os.walk(train_dir):\n",
    "        if len (files) > 0:\n",
    "            class_weights.append(1/len(files))\n",
    "\n",
    "    sample_weights =[0] *len(train_dataset)\n",
    "    for idx , (data , labels) in enumerate(tqdm(train_dataset.imgs)):\n",
    "        class_weight =class_weights[labels]\n",
    "        sample_weights[idx] = class_weight\n",
    "\n",
    "    sampler = WeightedRandomSampler(sample_weights , num_samples = len(sample_weights) , replacement = True)\n",
    "    train_loader = DataLoader(train_dataset , batch_size = batch_size , sampler =sampler ,num_workers= 2 , pin_memory=True )\n",
    "    return train_loader \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2781fafd-46c8-4542-9879-60d10cec9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "if len (physical_devices) > 0 :\n",
    "    tf.config.expremintal.set_memory_growth(physsical_devices[0] ,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74fbc48-5c61-47e2-92df-6b99d0244773",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 120\n",
    "NUM_EPOCHS = 3\n",
    "DATA_DIR = \"data/images/images\"\n",
    "MODEL_PATH = \"efficientb0/\"\n",
    "LOAD_MODEL = False\n",
    "\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] =\"1\"\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] =\"C://users/amrsa/save_b0_models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16999205-ea33-4ab1-aa41-5e1e5fbe1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(url, img_size, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(img_size, img_size, 3)), \n",
    "        tf.keras.layers.Lambda(lambda x: hub.KerasLayer(url)(x), trainable=True),  \n",
    "        tf.keras.layers.Dense(1000, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2073da89-f21d-4f0e-84ef-5d0ae92604b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(data , labels , acc_metrics , model , loss_fn ,optimizer ):\n",
    "    # data = data.premute(0 , 2 , 3 ,1)\n",
    "    # data = tf.convert_to_tensor(np.array(data))\n",
    "    # labels = tf.convert_to_tensor(np.array(labels))\n",
    "    with tf.GradientTape() as tape :\n",
    "        predictions = model (data , training =True )\n",
    "        loss = loss_fn (labels , predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss , model.trainable_weights  )\n",
    "    optimizer.apply_gradients(zip(gradients , model.trainable_weights))\n",
    "    acc_metrics.update_state(labels , predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dcc8dbe-6431-4315-a13c-c253ddef4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ds_validation):\n",
    "    acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "    for idx , (data ,labels) in enumerate(ds_validation) :\n",
    "        data = tf.convert_to_tensor(np.array(data))\n",
    "        labels = tf.convert_to_tensor(np.array(labels))\n",
    "        y_pred = model(data , training = False)\n",
    "        acc_metric.upate_state(labels , y_pred)\n",
    "\n",
    "    acc = acc_metric.results()\n",
    "    print(f'accuracy over validaion set {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d3c4af-ff6f-4d1c-b994-2ce316edfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_loader  = get_loaders(DATA_DIR ,  BATCH_SIZE , IMG_SIZE )\n",
    "    if LOAD_MODEL :\n",
    "        print ('loading model')\n",
    "        model = keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    else:\n",
    "        print ('building model')\n",
    "        model = get_model(URL , IMG_SIZE , NUM_CLASSES)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4)\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "    acc_metrics = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for idx , (data ,labels) in enumerate(tqdm(train_loader)):\n",
    "            data = data.permute(0 , 2 , 3 ,1)\n",
    "            data = tf.convert_to_tensor(np.array(data))\n",
    "            labels = tf.convert_to_tensor(np.array(labels))\n",
    "            train_step(data ,labels ,acc_metrics, model , loss_fn , optimizer)\n",
    "\n",
    "            if idx % 150 == 0 and idx > 0 :\n",
    "                train_acc = acc_metrics.result()\n",
    "                print (f\"accuracy over epoch (so far) {train_acc}\")\n",
    "\n",
    "                # evaluate_model(dev_loader , model)\n",
    "                model.save(\"efficientb0_model.keras\")\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105bea8a-158d-4d4d-a39d-ce2561ad75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20580/20580 [00:00<00:00, 1699723.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\version_utils.py:78: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n",
      "  0%|          | 0/644 [00:00<?, ?it/s]C:\\Users\\amrsa\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:602: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      " 23%|██▎       | 151/644 [01:24<03:23,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.5047599077224731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 301/644 [02:24<02:25,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.6344476938247681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 451/644 [03:23<01:17,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.6904795169830322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 601/644 [04:23<00:17,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7208298444747925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [04:51<00:00,  2.21it/s]\n",
      " 23%|██▎       | 151/644 [01:09<03:22,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7473634481430054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 301/644 [02:10<02:20,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7594664096832275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 451/644 [03:11<01:19,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7717639803886414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 601/644 [04:12<00:18,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7815985083580017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [04:30<00:00,  2.38it/s]\n",
      " 23%|██▎       | 151/644 [02:21<03:20,  2.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7920507788658142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 301/644 [03:20<02:14,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.7989643812179565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 451/644 [04:20<01:18,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.8050798773765564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 601/644 [05:21<00:17,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over epoch (so far) 0.8096601963043213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [05:39<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a6e32-4d99-4c76-9c1f-6c9d0a5b0c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
